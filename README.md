Virtual Mouse Using Hand Gestures

Overview

This project implements a Virtual Mouse that enables users to control their system using hand gestures, leveraging computer vision and deep learning techniques. It utilizes OpenCV for video processing, MediaPipe for hand tracking, and PyAutoGUI for simulating mouse actions. Additionally, users can control system brightness and volume through specific hand gestures.

Features

ğŸ¯ Cursor Control â€“ Move the mouse pointer using hand movements.
ğŸ–±ï¸ Clicking Actions:
Left Click â€“ Fist Gesture
Right Click â€“ Index Finger Gesture
Double Click â€“ Two-Finger Closed Gesture
ğŸ”„ Scrolling â€“ Scroll up/down using pinch gestures.
ğŸ”Š Volume Control â€“ Adjust system volume with a major pinch gesture.
ğŸ’¡ Brightness Control â€“ Adjust screen brightness with a minor pinch gesture.

Technologies Used

Python
OpenCV â€“ Real-time video processing
MediaPipe â€“ Hand tracking and gesture recognition
PyAutoGUI â€“ Simulating mouse actions
Screen Brightness Control â€“ Adjusting screen brightness
Pycaw â€“ Audio volume control

Prerequisites

Ensure you have Python 3.x installed, then install the required dependencies:
pip install opencv-python mediapipe pyautogui screen-brightness-control pycaw comtypes google protobuf

Usage

Run the Python script:
python virtual_mouse.py

The webcam will start detecting hand gestures.
Use the predefined gestures to control the mouse and system settings.
Press Enter to exit the program.
Hand Gesture Mapping
Gesture -	Action
V Gesture	- Move Cursor
Fist - Left Click
Index Finger - Right Click
Two Fingers Closed	- Double Click
Pinch Minor -	Scroll
Pinch Major -	Adjust Brightness / Volume

How It Works

âœ… Hand Tracking â€“ Uses MediaPipe Hands to track hand landmarks in real time.
âœ… Gesture Recognition â€“ Converts landmark positions into recognizable gestures.
âœ… Action Execution â€“ Maps detected gestures to corresponding mouse or system control actions.
âœ… Noise Reduction â€“ Uses a stabilization algorithm to prevent unintended movements.

Future Enhancements

ğŸš€ Gesture-Based Text Input â€“ Enable users to type using gestures.
ğŸš€ Improved Accuracy â€“ Enhance gesture detection using ML models.
ğŸš€ Multi-Hand Support â€“ Advanced gesture controls using both hands.

Contributors

ğŸ‘¨â€ğŸ’» Bobbili Hanuma Tanay
ğŸ‘¨â€ğŸ’» Indana Narsarao
ğŸ‘¨â€ğŸ’» Vanaparthi Purna chand

â­ If you like this project, give it a star! ğŸŒŸ
